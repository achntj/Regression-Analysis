{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7924549a-47c6-48a3-aeda-69bad42f505b",
   "metadata": {},
   "source": [
    "# Final Part II (50 pts)\n",
    "\n",
    "Before starting the exam, please make sure you have also downed the following two datasets in the __same__ folder of your Python exam file: `Maricopa.xlsx` and `njminrep.xlsx` on Canvas. After downloading everything, please close your Canvas page. \n",
    "\n",
    "### Instruction\n",
    "- The only application you can open in your computer is __one__ tab on your browser, which contains this Python Jupyter Notebook. \n",
    "    - If you open another tab or open another application in your computer, I will assume that you want to finish the exam by submitting your work. You will be asked to do so immediately and leave the exam room.\n",
    "- When you decide to submit __both__ your paper exam and your Python exam, open your Canvas and submit your Python exam.\n",
    "    - Please name your file as follows: `ECN310Final_LastName_FirstName.ipynb`.\n",
    "- After your submission, please double check with me that your file is successfully loaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a2e85",
   "metadata": {},
   "source": [
    "### Loading all potential libraries/packages\n",
    "Please run the following code to load all the potential libraries/packages that you may use in the exam. I have already typed the code for your convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86577807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats \n",
    "import statsmodels as sm\n",
    "import statsmodels.formula.api as smf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f1589",
   "metadata": {},
   "source": [
    "### Exercise 1 [25 points total]: Measurement error bias \n",
    "In this exercise, we will use the database that we have been using in class over the entire semester: Home sales in Maricopa county, `Maricopa.xlsx`. \n",
    "\n",
    "Below, I have typed the code to load data and named it as `house_df`. \n",
    "- Run the following code to load your data. \n",
    "- If you want to change the data to a different name, please feel free to change my code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2aadaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2178 entries, 0 to 2177\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sale_price    2178 non-null   int64  \n",
      " 1   area          2178 non-null   int64  \n",
      " 2   pool_area     2178 non-null   int64  \n",
      " 3   central_AC    2178 non-null   int64  \n",
      " 4   fixtures      2178 non-null   int64  \n",
      " 5   garage_count  2178 non-null   int64  \n",
      " 6   patio_count   2178 non-null   int64  \n",
      " 7   single_story  2178 non-null   int64  \n",
      " 8   year_built    2178 non-null   int64  \n",
      " 9   year_sold     2178 non-null   int64  \n",
      " 10  month_sold    2178 non-null   int64  \n",
      " 11  zipcode       2174 non-null   float64\n",
      " 12  city          2174 non-null   object \n",
      " 13  garage_type   2109 non-null   object \n",
      " 14  wall          2178 non-null   object \n",
      " 15  roof          2178 non-null   object \n",
      " 16  patio_type    1926 non-null   object \n",
      "dtypes: float64(1), int64(11), object(5)\n",
      "memory usage: 289.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "house_df = pd.read_excel('Maricopa.xlsx')\n",
    "house_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01388a72",
   "metadata": {},
   "source": [
    "We are interested in the following equation. We want to use it to test the theory of classical measurement error by artificially inducing classical measurement errors to the variable `area`.\n",
    "$$ğ‘ ğ‘ğ‘™ğ‘’\\_ğ‘ğ‘Ÿğ‘–ğ‘ğ‘’=\\beta_0+\\beta_1 ğ‘ğ‘Ÿğ‘’ğ‘+\\epsilon$$\n",
    "\n",
    "Here are the steps we would like to perform to validate our theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ee595",
   "metadata": {},
   "source": [
    "(1) [5 points] First, run the above regression using `sale_price` and `area`, and report the regression output. Make sure you use the `print()` function to report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8783fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             sale_price   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.504\n",
      "Method:                 Least Squares   F-statistic:                     2211.\n",
      "Date:                Thu, 12 Dec 2024   Prob (F-statistic):               0.00\n",
      "Time:                        13:23:20   Log-Likelihood:                -28330.\n",
      "No. Observations:                2178   AIC:                         5.666e+04\n",
      "Df Residuals:                    2176   BIC:                         5.668e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3930.8095   6695.297      0.587      0.557   -9199.035    1.71e+04\n",
      "area         138.3707      2.943     47.020      0.000     132.600     144.142\n",
      "==============================================================================\n",
      "Omnibus:                      395.268   Durbin-Watson:                   1.952\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1447.758\n",
      "Skew:                           0.864   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.601   Cond. No.                     6.59e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.59e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Please write your executable code here\n",
    "results = smf.ols('sale_price ~ area', data=house_df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e168090-d212-476a-9749-ce8117d55d9b",
   "metadata": {},
   "source": [
    "(2) [10 points] Simulate a variable called `error` from a normal distribution with mean = 0 and standard deviation = std(ğ‘ğ‘Ÿğ‘’ğ‘), i.e., the standard deviation of the variable `area`. \n",
    "- _Hints_: calculate the standard deviation of `area` first, then create the variable `error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd73cfc-a628-42c5-9298-8a5ce9edcc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sale_price  area  pool_area  central_AC  fixtures  garage_count  \\\n",
      "0         345000  2015          0           1         7             2   \n",
      "1         377500  2919        475           1        11             3   \n",
      "2         423039  2044          0           1         7             3   \n",
      "3         333341  1754          0           1         7             2   \n",
      "4         207000  1680        420           1         8             2   \n",
      "...          ...   ...        ...         ...       ...           ...   \n",
      "2173      235500  1656        461           1         6             2   \n",
      "2174      765000  2571        450           1        11             2   \n",
      "2175      465000  2763        500           1        12             2   \n",
      "2176      270000  1614          0           1         7             2   \n",
      "2177      166000  1738          0           1         6             2   \n",
      "\n",
      "      patio_count  single_story  year_built  year_sold  month_sold  zipcode  \\\n",
      "0               1             1        2001       2018           6  85374.0   \n",
      "1               1             1        1991       2019           1  85048.0   \n",
      "2               1             1        2016       2017           9  85383.0   \n",
      "3               2             1        2016       2016          11  85085.0   \n",
      "4               1             1        2003       2017           3  85379.0   \n",
      "...           ...           ...         ...        ...         ...      ...   \n",
      "2173            1             1        1973       2016           9  85053.0   \n",
      "2174            2             0        1984       2017          10  85258.0   \n",
      "2175            2             0        1997       2017           8  85284.0   \n",
      "2176            1             1        1996       2016           4  85248.0   \n",
      "2177            1             1        1979       2017           5  85375.0   \n",
      "\n",
      "               city garage_type                  wall             roof  \\\n",
      "0          SURPRISE      Garage            Frame Wood    Concrete Tile   \n",
      "1           PHOENIX      Garage            Frame Wood    Concrete Tile   \n",
      "2            PEORIA      Garage                 Other    Concrete Tile   \n",
      "3           PHOENIX      Garage                 Other    Concrete Tile   \n",
      "4          SURPRISE      Garage            Frame Wood    Concrete Tile   \n",
      "...             ...         ...                   ...              ...   \n",
      "2173        PHOENIX      Garage  8 Inch Painted Block  Asphalt Shingle   \n",
      "2174     SCOTTSDALE      Garage            Frame Wood             Tile   \n",
      "2175          TEMPE      Garage            Frame Wood    Concrete Tile   \n",
      "2176      SUN LAKES      Garage         8 Inch Stucco    Concrete Tile   \n",
      "2177  SUN CITY WEST      Garage            Frame Wood  Asphalt Shingle   \n",
      "\n",
      "     patio_type        error  \n",
      "0         Cover -1740.423653  \n",
      "1         Cover  1142.902815  \n",
      "2         Cover  1500.040374  \n",
      "3         Cover  1058.982211  \n",
      "4         Cover   767.306297  \n",
      "...         ...          ...  \n",
      "2173       Slab   198.884554  \n",
      "2174      Cover   442.149999  \n",
      "2175      Cover  1597.113180  \n",
      "2176      Cover   129.104664  \n",
      "2177      Cover -1424.976396  \n",
      "\n",
      "[2178 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "# Please write your executable code here\n",
    "std = np.std(house_df['area'])\n",
    "house_df['error'] = np.random.normal(0, std, size=len(house_df['area']))\n",
    "print(house_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8e8ff-e42c-4200-b9e0-a1ac99dd4adc",
   "metadata": {},
   "source": [
    "(3) [5 points] Create a variable called `area_error` that is equal to `area` + `error`. And then run the above regression using `sale_price` and `area_error` instead, i.e., \n",
    "\n",
    "$$ğ‘ ğ‘ğ‘™ğ‘’\\_ğ‘ğ‘Ÿğ‘–ğ‘ğ‘’=ğ›¼_0+ğ›¼_1 ğ‘ğ‘Ÿğ‘’ğ‘\\_ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ+ğœ–$$\n",
    "\n",
    "\n",
    "Again, make sure you use the `print()` function to report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89fb340a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             sale_price   R-squared:                       0.245\n",
      "Model:                            OLS   Adj. R-squared:                  0.244\n",
      "Method:                 Least Squares   F-statistic:                     705.1\n",
      "Date:                Thu, 12 Dec 2024   Prob (F-statistic):          8.27e-135\n",
      "Time:                        13:23:20   Log-Likelihood:                -28788.\n",
      "No. Observations:                2178   AIC:                         5.758e+04\n",
      "Df Residuals:                    2176   BIC:                         5.759e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1.509e+05   6276.863     24.044      0.000    1.39e+05    1.63e+05\n",
      "area_error    69.0928      2.602     26.553      0.000      63.990      74.196\n",
      "==============================================================================\n",
      "Omnibus:                      477.229   Durbin-Watson:                   1.954\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1087.861\n",
      "Skew:                           1.221   Prob(JB):                    5.94e-237\n",
      "Kurtosis:                       5.454   Cond. No.                     5.31e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.31e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Please write your executable code here\n",
    "house_df['area_error'] = house_df['area'] + house_df['error']\n",
    "results2 = smf.ols('sale_price ~ area_error', data=house_df).fit()\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85bc725-8e9f-4b6a-955f-cc0234eec00f",
   "metadata": {},
   "source": [
    "(4) [2 points] According the two regression output, what is your conclusion on the direction of bias with classical measurement error on `area`? \n",
    "\n",
    "_Hints_: Compare the size of $\\alpha_1$ and $\\beta_1$ in the two regression tables."
   ]
  },
  {
   "cell_type": "raw",
   "id": "49d7e3d7-6d5e-41a6-bea7-f1ea5f716e1b",
   "metadata": {},
   "source": [
    "Write your answer to above question here.\n",
    "\n",
    "alpha_1 is less than beta_1 so there is a downward bias. We underestimate the coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421cb93-bf0d-4422-a63e-9142128495bb",
   "metadata": {},
   "source": [
    "(5) [3 points] We have a name for this kind of bias. What is the name of the bias? \n",
    "\n",
    "_Hints_: Do __not__ write _measurement error bias_. If you do not remember the exact name of the bias, it is totally fine to me. Instead, please state the _simple_ property of the bias below. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "17d76fa8-5614-4340-9f24-ea176676b09e",
   "metadata": {},
   "source": [
    "Write your answer to above question here.\n",
    "\n",
    "\n",
    "Attenuation Bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e5d852-ef88-4ef2-b185-e3cc77a35566",
   "metadata": {},
   "source": [
    "### Exercise 2 [25 points total]: Difference-in-differences: Card and Kreguer (1994 AER)\n",
    "In this exercise, we will replicate one of the most famamous applications in Difference-in-differences, which serves as one of the central contributions to David Card's Nobel prize in 2021. \n",
    "\n",
    "This paper studies the effect of increasing min. wage on employment in the fast-food industry. Specifically, the authors want to utilize the fact that the min. wage policy is increased on 04/01/1992 in New Jersey but not in the neighboring state Pennsylvania, and adopt a difference-in-differences approach. \n",
    "\n",
    "We want to replicate their main results by running the following difference-in-differences regression:\n",
    "\n",
    "$$ğ‘¦= ğ›½_0+ ğ›½_1 ğ‘ƒğ‘œğ‘ ğ‘¡+ ğ›½_2 ğ‘‡ğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘šğ‘’ğ‘›ğ‘¡+ ğ›½_3 ğ‘‡ğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘šğ‘’ğ‘›ğ‘¡âˆ—ğ‘ƒğ‘œğ‘ ğ‘¡+ ğœ–$$\n",
    "\n",
    "- y is the number of worker in each restaurant\n",
    "- Treatment = 1 if the restaurant is in NJ; = 0 otherwise\n",
    "- Post = 1 if the time is after 04/01/1992; = 0 otherwise\n",
    "\n",
    "To do so, please use the dataset `njminrep.xlsx`, which contains the following five variables: \n",
    "- `store_id`: the unique ID\n",
    "- `state`: NJ or PA\n",
    "- `year`: 1992\n",
    "- `month`: Feb or Nov (remember that the policy happens in April)\n",
    "- `totemp`: total number of workers in the restaurant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff0bd6",
   "metadata": {},
   "source": [
    "Below, I have typed the code to load data and named it as `df`. \n",
    "- Run the following code to load the data. \n",
    "- If you want to change the data to a different name, please feel free to change my code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca72920-3a9d-4a3a-baf1-a45e0a971865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   store_id  768 non-null    int64  \n",
      " 1   state     768 non-null    object \n",
      " 2   year      768 non-null    int64  \n",
      " 3   month     768 non-null    object \n",
      " 4   totemp    768 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 30.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_excel('njminrep.xlsx')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47779741",
   "metadata": {},
   "source": [
    "(1) [15 points] Using the data, replicate the main result of the paper by running its main difference-in-differences regression. \n",
    "\n",
    "You may choose to follow the steps below. \n",
    "- create two dummy variables: `treatment` and `post` according to the description above.\n",
    "- create an interaction term using these two dummy varibles.\n",
    "- run the difference-in-differences regression using the new variables you have created.\n",
    "\n",
    "Make sure that you use `print()` to report the regression result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38eba94-03af-4dd1-9063-20ba6642ed6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "1992    768\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d5f8d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 totemp   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     1.947\n",
      "Date:                Thu, 12 Dec 2024   Prob (F-statistic):              0.121\n",
      "Time:                        13:23:20   Log-Likelihood:                -2817.6\n",
      "No. Observations:                 768   AIC:                             5643.\n",
      "Df Residuals:                     764   BIC:                             5662.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         23.3800      1.098     21.288      0.000      21.224      25.536\n",
      "post              -2.2833      1.553     -1.470      0.142      -5.332       0.766\n",
      "treatment         -2.9494      1.224     -2.409      0.016      -5.353      -0.546\n",
      "post_treatment     2.7500      1.731      1.588      0.113      -0.649       6.149\n",
      "==============================================================================\n",
      "Omnibus:                      212.243   Durbin-Watson:                   1.384\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              761.734\n",
      "Skew:                           1.278   Prob(JB):                    3.90e-166\n",
      "Kurtosis:                       7.155   Cond. No.                         11.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Please write your executable code here\n",
    "df['treatment'] = (df['state'] == 'nj').astype(int)\n",
    "df['post'] = (df['month'] == 'nov').astype(int) # since there is only the year 1992 we dont need to check for year >= 1992\n",
    "df['post_treatment'] = df['treatment'] * df['post']\n",
    "results3 = smf.ols('totemp ~ post + treatment + post_treatment', data=df).fit()\n",
    "print(results3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af2082",
   "metadata": {},
   "source": [
    "(2) [5 points] From your regression table, can you what is your estimate of the DiD estimator? Is it statistically significant at 5% level?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc12ae45",
   "metadata": {},
   "source": [
    "Write your answer to above question here.\n",
    "\n",
    "The DiD estimator is given by Beta_3 and is equal to 2.75. At alpha = 0.05, it is not statistically significant because the p-value is 0.113 > 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a4119",
   "metadata": {},
   "source": [
    "(3) [5 points] Suppose that Card and Krueger have provided all the evidence we need to claim the DiD estimator is a causal effect. What is your final conclusion on the effect of the min wage increase on employment? \n",
    "\n",
    "_Hints_: Make sure you take the standard error of the DiD estimator into consideration while drawing your final conclusion. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "806e3647",
   "metadata": {},
   "source": [
    "Write your answer to above question here.\n",
    "\n",
    "Even though we are given that the parallel trends assumption is true, since the DiD is not statiscally significant (p-value < alpha) we can not draw any causal relationship on the effect of minimum wage increase on employment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
